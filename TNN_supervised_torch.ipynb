{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch # tested under pytorch 0.4.0\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1) # Fix seed of the random number generators\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_imgs(imgs,l1=4,l2=5,s1=6,s2=6):\n",
    "    \"\"\"    Plot images    \"\"\"\n",
    "    plt.rcParams['figure.figsize']=(s1,s2)\n",
    "    imgs=imgs.reshape([-1,28,28])\n",
    "    g, ax = plt.subplots(l1,l2)\n",
    "    for i in range(l1):\n",
    "        for j in range(l2):\n",
    "            a=i*l1+j\n",
    "            if(a>=imgs.shape[0]):\n",
    "                break\n",
    "            ax[i][j].imshow(imgs[a,:,:],cmap='summer')\n",
    "            ax[i][j].set_xticks([])\n",
    "            ax[i][j].set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 784\n",
    "m = 20\n",
    "data = np.load(\"imgs/mnist_100_28x28_p0.5.npy\")\n",
    "data = data[:m, :, :]\n",
    "data = torch.LongTensor(data)\n",
    "data = data.view(-1, 784)\n",
    "show_imgs(data, 2, 10, 10, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Building blocks of the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Forward\n",
    "\\begin{align*}\n",
    "&f^{l}(x) = \\frac{1}{m}\\sum_{i}{[A^{s_{1}}_{\\alpha_{0}\\alpha_{1}}\\cdots A^{s_{n}}_{\\alpha_{n-1}\\alpha_{n}}\\Phi^{s_{1}s_{2}\\cdots s_{n}}(x^{i})]}\\\\\n",
    "&L = \\frac{1}{m}\\sum_{i}{[f^{l}(x_{i}) - \\delta^{l}_{n}]^{2}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_initialize(n_x, Dmax, l):\n",
    "    \"\"\"\n",
    "    Initialize the tensor network.\n",
    "    \n",
    "    Arguments:\n",
    "    paramters -- python dictionary containing:\n",
    "                    m -- Number of samples in one batch\n",
    "                    n -- Number of features\n",
    "                    Dmax -- Bond dimensions\n",
    "                    l -- Sites of the output tensor\n",
    "    \n",
    "    Returns:\n",
    "    tensors -- MPS, list of pytorch tensors\n",
    "    \"\"\"\n",
    "    bond_dims = [Dmax for i in range(n - 1)] + [1]\n",
    "    tensors = []\n",
    "    for i in range(n):\n",
    "        if i != l:\n",
    "            tensors.append(torch.randn(bond_dims[i-1], 2, bond_dims[i]))\n",
    "        else:\n",
    "            tensors.append(torch.randn(bond_dims[i-1], 2, index, bond_dims[i]))\n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnn_cell_forward(X, Y, parameters):\n",
    "    m, n = X.shape\n",
    "    tensors, l = parameters['tensors'], parameters['l']\n",
    "    psi = torch.ones([m, 1, 1])\n",
    "    assert l < n-1, \"invalid l!\"\n",
    "    for site in range(l):\n",
    "        psi = psi @ tensors[site][:, X[:, site], :].permute(1, 0, 2)\n",
    "    left_psi = psi\n",
    "    psi = psi @ tensors[l][:, X[:, l], :, :].permute(2, 1, 0, 3) @ tensors[l+1][:, X[:, l+1], :].permute(1, 0, 2)\n",
    "    if l == n - 2:\n",
    "        right_psi = torch.ones([m, 1, 1])\n",
    "    else:\n",
    "        right_psi = torch.ones([m, tensors[l+1].shape[2], tensors[l+1].shape[2]])\n",
    "        for site in range(l+2, n):\n",
    "            psi = psi @ tensors[site][:, X[:, site], :].permute(1, 0, 2)\n",
    "            right_psi = right_psi @ tensors[site][:, X[:, site], :].permute(1, 0, 2)\n",
    "    cache = (left_psi, right_psi, psi)\n",
    "    loss = torch.sum(torch.pow(psi.squeeze()-Y.transpose(0, 1), 2)) / m\n",
    "    return loss, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([1, 2, 5])\n",
      "torch.Size([5, 2, 5])\n",
      "torch.Size([5, 2, 5])\n",
      "torch.Size([5, 2, 10, 5])\n",
      "torch.Size([5, 2, 5])\n",
      "torch.Size([5, 2, 5])\n",
      "torch.Size([5, 2, 5])\n",
      "torch.Size([5, 2, 5])\n",
      "torch.Size([5, 2, 5])\n",
      "torch.Size([5, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "#test for the tensor_initialize() \n",
    "#torch.manual_seed(1)\n",
    "m, n, l, index = 5, 10, 3, 10\n",
    "Dmax = 5\n",
    "#tensors = [torch.randn(bond_dims[-1], 2, 10, bond_dims[0])] + [torch.randn(bond_dims[i-1], 2, bond_dims[i]) for i in range(1, n)]\n",
    "tensors = tensor_initialize(n, Dmax, l)\n",
    "parameters = {'m': m, 'n': n, 'Dmax': Dmax, 'index': 10, 'l': l, 'tensors': tensors}\n",
    "print(len(tensors))\n",
    "for i in range(n):\n",
    "    print(tensors[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(Y, index):\n",
    "    \"\"\"\n",
    "    encode the label of the training set as one hot vector.\n",
    "    \n",
    "    Arguments:\n",
    "    Y -- labels of the samples, numpy vector with dimension as (m, 1)\n",
    "    \n",
    "    Return:\n",
    "    Y_onehot -- labels of the samples, pytorch tensor with dimension as (m, index)\n",
    "    \"\"\"\n",
    "    m = Y.shape[0]\n",
    "    Y_onehot = torch.zeros(m, index, dtype=torch.float32).scatter_(1, torch.LongTensor(Y.reshape(m, 1)), torch.ones(m, index, dtype=torch.float32))\n",
    "    \n",
    "    return Y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 5])\n",
      "torch.Size([5, 2, 5])\n",
      "torch.Size([5, 2, 5])\n",
      "torch.Size([5, 2, 5])\n",
      "torch.Size([5, 2, 5])\n",
      "torch.Size([5, 2, 5])\n",
      "torch.Size([5, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 10, 5])\n",
      "torch.Size([5, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "for i in range(n):\n",
    "    print(tensors[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sample in one batch is:  5\n",
      "number of features of one sample is:  10\n",
      "output shape is:  torch.Size([10, 5, 1, 1])\n",
      "shape of left tensor of Al is:  torch.Size([5, 1, 5])\n",
      "shape of right tensor of Al is:  torch.Size([5, 5, 1])\n",
      "the loss is:  tensor(1585972.2500)\n"
     ]
    }
   ],
   "source": [
    "#test for tnn_forward() module\n",
    "X = torch.randint(1, (m, n))\n",
    "loss, cache = tnn_cell_forward(X, Y_onehot, parameters)\n",
    "(left_psi, right_psi, psi) = cache\n",
    "print(\"number of sample in one batch is: \", m)\n",
    "print(\"number of features of one sample is: \", n)\n",
    "print(\"output shape is: \", psi.shape)\n",
    "print(\"shape of left tensor of Al is: \", left_psi.shape)\n",
    "print(\"shape of right tensor of Al is: \", right_psi.shape)\n",
    "print(\"the loss is: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Backward\n",
    "\\begin{align*}\n",
    "&\\frac{\\partial{L}}{\\partial{f^{l}(x^{(i)})}} = 2(f^{l}(x_{i}) - \\delta^{l}_{n})\\\\\n",
    "&\\frac{\\partial{f^{l}(x^{(i)})}}{\\partial{B^{l,s_{k}s_{k+1}}_{\\alpha_{k-1}\\alpha_{k+1}}}} = \\tilde{A}^{s_{1}s_{2}\\cdots s_{k-1}}_{\\alpha_{k-1}}\\tilde{B}^{s_{k+2}\\cdots s_{n}}_{\\alpha_{k+1}}\\Phi^{s_{1}s_{2}\\cdots s_{n}}(x^{(i)})\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(Y, index):\n",
    "    \"\"\"\n",
    "    encode the label of the training set as one hot vector.\n",
    "    \n",
    "    Arguments:\n",
    "    Y -- labels of the samples, numpy vector with dimension as (m, 1)\n",
    "    \n",
    "    Return:\n",
    "    Y_onehot -- labels of the samples, pytorch tensor with dimension as (m, index)\n",
    "    \"\"\"\n",
    "    m = Y.shape[0]\n",
    "    Y_onehot = torch.zeros(m, index, dtype=torch.float32).scatter_(1, torch.LongTensor(Y.reshape(m, 1)), torch.ones(m, index, dtype=torch.float32))\n",
    "    \n",
    "    return Y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels of the raw data:  [6 5 5 3 4]\n",
      "one-hot vector of labels:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#test for module one_hot()\n",
    "Y = np.random.binomial(index, 0.5, m)\n",
    "Y_onehot = one_hot(Y, index)\n",
    "print(\"labels of the raw data: \", Y)\n",
    "print(\"one-hot vector of labels: \", Y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnn_cell_backward(X, Y, cache, parameters):\n",
    "    \"\"\"\n",
    "    Calculate the gradients of the loss function wrt mps.\n",
    "    \n",
    "    Arguments:\n",
    "    Y -- labels of the samples, pytorch tensor with dimension (m, index)\n",
    "    \n",
    "    Return:\n",
    "    dAl -- gradient of the tensor, pytorch tensor with dimension (m, index, alpha_lf, alpha_rig)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    left_psi, right_psi, psi = cache\n",
    "    l =  parameters['l']\n",
    "    left_index, right_index = left_psi.shape[-1], right_psi.shape[-2]\n",
    "    m = X.shape[0]\n",
    "    index = parameters['index']\n",
    "    dfl = 2 * (psi - Y.reshape_as(psi))\n",
    "    dBl_m = dfl * (left_psi.transpose(1, 2) @ right_psi.transpose(1, 2))\n",
    "    index1, index2 = (X[:, l] == 0).view(1, -1, 1, 1), (X[:, l+1] == 0).view(1, -1, 1, 1)\n",
    "    index3, index4 = 1 - index1, 1 - index2\n",
    "    dBl_1 = (dBl_m * (index1 * index2).type(torch.float)).mean(1, True)\n",
    "    dBl_2 = (dBl_m * (index1 * index4).type(torch.float)).mean(1, True)\n",
    "    dBl_3 = (dBl_m * (index3 * index2).type(torch.float)).mean(1, True)\n",
    "    dBl_4 = (dBl_m * (index3 * index4).type(torch.float)).mean(1, True)\n",
    "    dBl = torch.cat((dBl_1, dBl_2, dBl_3, dBl_4), 1).reshape(index, 2, 2, left_index, right_index)\n",
    "    \n",
    "    gradients = {'dBl': dBl}\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradients of tensor Bl:  torch.Size([10, 2, 2, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "#test for tnn_cell_backward()\n",
    "gradients = tnn_cell_backward(X, Y_onehot, cache, parameters)\n",
    "dBl = gradients['dBl']\n",
    "print(\"gradients of tensor Bl: \", dBl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\Delta B^{l,s_{k-1}s_{k}}_{\\alpha_{k-1}\\alpha_{k+1}}\\to\n",
    "\\begin{bmatrix}\n",
    "B^{l,x_{m}}_{\\alpha_{k-1}\\alpha_{k+1}}\\\\\n",
    "\\cdots\\\\\n",
    "B^{l,x_{n}}_{\\alpha_{k-1}\\alpha_{k+1}}\n",
    "\\end{bmatrix}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(X, parameters, gradients, bond, learning_rate):\n",
    "    \n",
    "    m, n, index, tensors, l = parameters['m'], parameters['n'], parameters['index'], parameters['tensors'], parameters['l']\n",
    "    assert l < n, \"invalid l\"\n",
    "    dBl = gradients['dBl']\n",
    "    Bl = tensors[l].permute(2, 1, 0, 3).unsqueeze(2) @ tensors[l+1].permute(1, 0, 2).unsqueeze(0)\n",
    "    Bl +=  dBl\n",
    "    alpha_left, alpha_right = dBl.shape[-2], dBl.shape[-1]\n",
    "    u, s, vt = torch.svd(Bl.permute(1, 3, 0, 2, 4).contiguous().view(2*alpha_left, 2*alpha_right*index))\n",
    "    tensors[l] = ((u * s).split(bond, 1)[0]).reshape(2, alpha_left, bond).permute(1, 0, 2)\n",
    "    tensors[l+1] = (((vt.transpose(0, 1)).split(bond, 0))[0]).reshape(bond, index, 2, alpha_right).permute(0, 2, 1, 3)\n",
    "    parameters['l'] = l + 1      \n",
    "    \n",
    "    return parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated A^{l} tensor:  torch.Size([5, 2, 1])\n",
      "updated A^{l+1} tensor:  torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 5])\n",
      "torch.Size([5, 2, 5])\n",
      "torch.Size([5, 2, 5])\n",
      "torch.Size([5, 2, 5])\n",
      "torch.Size([5, 2, 5])\n",
      "torch.Size([5, 2, 5])\n",
      "torch.Size([5, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 10, 5])\n",
      "torch.Size([5, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "#test for update_parameters()\n",
    "bond, learning_rate, n = 1, 0.01, parameters['n']\n",
    "parameters = update_parameters(X, parameters, gradients, bond, learning_rate)\n",
    "tensors = parameters['tensors']\n",
    "print(\"updated A^{l} tensor: \", tensors[l].shape)\n",
    "print(\"updated A^{l+1} tensor: \", tensors[l+1].shape)\n",
    "for i in range(n):\n",
    "    print(tensors[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(X, Y, parameters, bond, learning_rate=0.01):\n",
    "    \n",
    "    n, l = parameters['n'], parameters['l']\n",
    "    for i in range(n):\n",
    "        if l > (n - 2):\n",
    "            break\n",
    "        loss, cache = tnn_cell_forward(X, Y, parameters)\n",
    "        gradients = tnn_cell_backward(X, Y, cache, parameters)\n",
    "        parameters = update_parameters(X, parameters, gradients, bond, learning_rate)\n",
    "        l = l + 1\n",
    "    \n",
    "    return parameters, loss, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 5])\n",
      "torch.Size([5, 2, 5])\n",
      "torch.Size([5, 2, 5])\n",
      "torch.Size([5, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 10, 1])\n",
      "torch.Size([10, 2, 2, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "#test for optimize()\n",
    "tensor_initialize(n, Dmax, l)\n",
    "parameters, loss, gradients = optimize(X, Y_onehot, parameters, bond, learning_rate)\n",
    "n, tensors = parameters['n'], parameters['tensors']\n",
    "dAl = gradients['dBl']\n",
    "for i in range(n):\n",
    "    print(tensors[i].shape)\n",
    "print(dAl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
